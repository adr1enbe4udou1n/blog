---
title: "A 2024 benchmark of main Web API frameworks"
date: 2023-12-26
tags: ["kubernetes", "docker", "load-testing", "k6", "webapi"]
---

{{< lead >}}
We'll be comparing the read performance of 6 Web APIs frameworks, sharing the same OpenAPI contract from [realworld app](https://github.com/gothinkster/realworld), a medium-like clone, implemented under multiple languages (PHP, Python, Javascript, Java and C#). Updated in 09/2024.
{{< /lead >}}

{{< alert >}}
Outdated post, check the [lastest]({{< ref "/posts/23-web-api-benchmarks-2025" >}}) for updated benchs.
{{< /alert >}}

This is not a basic synthetic benchmark, but a real world benchmark with DB data tests, and multiple scenarios. This post may be updated when new versions of frameworks will be released or any suggestions for performance related improvement in below commentary section.

A state of the art of real world benchmarks comparison of Web APIs is difficult to achieve and very time-consuming as it forces mastering each framework. As performance can highly dependent of:

- Code implementation, all made by my own
- Fine-tuning for each runtime, so I mostly take the default configuration

Now that's said, let's fight !

## The contenders

We'll be using the very last up-to-date stable versions of each framework, and the latest stable version of the runtime.

I give you all source code as well as public OCI artifacts of each project, so you can test it by yourself quickly.

| Framework & Source code                                                                                                                                                                                                            | Runtime        | ORM            |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------- | -------------- |
| [Laravel 11](https://github.com/adr1enbe4udou1n/laravel-realworld-example-app) ([api](https://laravelrealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/laravel/latest))                 | FrankenPHP 8.3 | Eloquent       |
| [Symfony 7](https://github.com/adr1enbe4udou1n/symfony-realworld-example-app) ([api](https://symfonyrealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/symfony/latest))                  | FrankenPHP 8.3 | Doctrine       |
| [FastAPI](https://github.com/adr1enbe4udou1n/fastapi-realworld-example-app) ([api](https://fastapirealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/fastapi/latest))                    | Python 3.12    | SQLAlchemy 2.0 |
| [NestJS 10](https://github.com/adr1enbe4udou1n/nestjs-realworld-example-app) ([api](https://nestjsrealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/nestjs/latest))                     | Node 20        | Prisma 5       |
| [Spring Boot 3.3](https://github.com/adr1enbe4udou1n/spring-boot-realworld-example-app) ([api](https://springbootrealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/spring-boot/latest)) | Java 21        | Hibernate 6    |
| [ASP.NET Core 8](https://github.com/adr1enbe4udou1n/aspnetcore-realworld-example-app) ([api](https://aspnetcorerealworld.okami101.io/api/) / [image](https://gitea.okami101.io/conduit/-/packages/container/aspnet-core/latest))   | .NET 8.0       | EF Core 8      |

Each project are:

- Using PostgreSQL
- Using the same OpenAPI contract
- Fully tested and functional against same [Postman collection](https://github.com/gothinkster/realworld/blob/main/api/Conduit.postman_collection.json)
- Highly tooled with high code quality in mind (static analyzers, formatter, linters, good code coverage, etc.)
- Share roughly the same amount of DB datasets, 50 users, 500 articles, 5000 comments, generated by faker-like library for each language
- Avoiding N+1 queries with eager loading (normally)
- Containerized with Docker, and deployed on a monitored Docker Swarm cluster

## The Swarm cluster for testing

We'll be running all Web APIs project on a Docker swarm cluster, where each node are composed of 2 dedicated CPUs for stable performance and 8Â GB of RAM. I'll use 4 CCX13 instances from Hetzner.

Traefik will be used as a reverse proxy, load balancing the requests to the replicas of each node.

{{< mermaid >}}
flowchart TD
client((k6))
client -- Port 80 443 --> traefik-01
subgraph manager-01
    traefik-01{Traefik SSL}
end
subgraph worker-01
    app-01([Conduit replica 1])
    traefik-01 --> app-01
end
subgraph worker-02
    app-02([Conduit replica 2])
    traefik-01 --> app-02
end
subgraph storage-01
    DB[(PostgreSQL)]
    app-01 --> DB
    app-02 --> DB
end
{{< /mermaid >}}

The Swarm cluster is fully monitored with [Prometheus](https://prometheus.io/) and [Grafana](https://grafana.com/), allowing to get relevant performance result.

Here is the complete [terraform swarm bootstrap](https://github.com/adr1enbe4udou1n/terraform-swarm-okami) if you want to reproduce the same setup.

## The deployment configuration

Following is the deployment configuration for each framework, using Docker Swarm stack file.

{{< tabs >}}
{{< tab tabName="Laravel" >}}

{{< highlight file="deploy-laravel.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/laravel:latest
    environment:
      - APP_KEY=base64:nltxnFb9OaSAr4QcCchy8dG1QXUbc2+2tsXpzN9+ovg=
      - DB_CONNECTION=pgsql
      - DB_HOST=postgres_db
      - DB_USERNAME=okami
      - DB_PASSWORD=okami
      - DB_DATABASE=conduit_laravel
      - JWT_SECRET_KEY=c2b344e1-1a20-47fc-9aef-55b0c0d568a7
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.laravel.entrypoints=websecure
        - traefik.http.services.laravel.loadbalancer.server.port=8000
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< tab tabName="Symfony" >}}

{{< highlight file="deploy-symfony.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/symfony:latest
    environment:
      - SERVER_NAME=:80
      - APP_SECRET=ede04f29dd6c8b0e404581d48c36ec73
      - DATABASE_URL=postgresql://okami:okami@postgres_db/conduit_symfony
      - DATABASE_RO_URL=postgresql://okami:okami@postgres_db/conduit_symfony
      - JWT_PASSPHRASE=c2b344e1-1a20-47fc-9aef-55b0c0d568a7
      - FRANKENPHP_CONFIG=worker ./public/index.php
      - APP_RUNTIME=Runtime\FrankenPhpSymfony\Runtime
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.symfony.entrypoints=websecure
        - traefik.http.services.symfony.loadbalancer.server.port=80
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< tab tabName="FastAPI" >}}

{{< highlight file="deploy-fastapi.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/fastapi:latest
    environment:
      - DB_HOST=postgres_db
      - DB_RO_HOST=postgres_db
      - DB_PORT=5432
      - DB_USERNAME=okami
      - DB_PASSWORD=okami
      - DB_DATABASE=conduit_fastapi
      - JWT_PASSPHRASE=c2b344e1-1a20-47fc-9aef-55b0c0d568a7
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.fastapi.entrypoints=websecure
        - traefik.http.services.fastapi.loadbalancer.server.port=8000
      replicas: 4
      placement:
        max_replicas_per_node: 2
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< tab tabName="NestJS" >}}

{{< highlight file="deploy-nestjs.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/nestjs:latest
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgres://okami:okami@postgres_db/conduit_nestjs
      - JWT_SECRET=c2b344e1-1a20-47fc-9aef-55b0c0d568a7
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.nestjs.entrypoints=websecure
        - traefik.http.services.nestjs.loadbalancer.server.port=3000
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< tab tabName="Spring Boot" >}}

{{< highlight file="deploy-spring-boot.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/spring-boot:latest
    environment:
      - SPRING_PROFILES_ACTIVE=production
      - DB_HOST=postgres_db
      - DB_PORT=5432
      - DB_RO_HOST=postgres_db
      - DB_USERNAME=okami
      - DB_PASSWORD=okami
      - DB_DATABASE=conduit_springboot
      - JWT_SECRET_KEY=YzJiMzQ0ZTEtMWEyMC00N2ZjLTlhZWYtNTViMGMwZDU2OGE3
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.springboot.entrypoints=websecure
        - traefik.http.services.springboot.loadbalancer.server.port=8080
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< tab tabName="ASP.NET Core" >}}

{{< highlight file="deploy-aspnet-core.yml" >}}

```yml
version: "3.8"

services:
  app:
    image: gitea.okami101.io/conduit/symfony:latest
    environment:
      - SERVER_NAME=:80
      - APP_SECRET=ede04f29dd6c8b0e404581d48c36ec73
      - DATABASE_DRIVER=pdo_pgsql
      - DATABASE_URL=postgresql://okami:okami@postgres_db/conduit_symfony
      - DATABASE_RO_URL=postgresql://okami:okami@postgres_db/conduit_symfony
      - JWT_PASSPHRASE=c2b344e1-1a20-47fc-9aef-55b0c0d568a7
      - FRANKENPHP_CONFIG=worker ./public/index.php
      - APP_RUNTIME=Runtime\FrankenPhpSymfony\Runtime
    networks:
      - postgres_db
      - traefik_public
    deploy:
      labels:
        - traefik.enable=true
        - traefik.http.routers.symfony.entrypoints=websecure
        - traefik.http.services.symfony.loadbalancer.server.port=80
      replicas: 2
      placement:
        max_replicas_per_node: 1
        constraints:
          - node.labels.run == true

networks:
  postgres_db:
    external: true
  traefik_public:
    external: true
```

{{< /highlight >}}

{{< /tab >}}
{{< /tabs >}}

Once the Swarm cluster is ready with all proxy, monitoring, database tools initialized, create all associated databases and let's deploy each project as following :

```bash
docker stack deploy laravel -c deploy-laravel.yml
docker stack deploy symfony -c deploy-symfony.yml
docker stack deploy fastapi -c deploy-fastapi.yml
docker stack deploy nestjs -c deploy-nestjs.yml
docker stack deploy spring-boot -c deploy-spring-boot.yml
docker stack deploy aspnet-core -c deploy-aspnet-core.yml
```

Once deployed you must migrate and seed the database according each project, check associated README for info.

## The k6 scenarios

We'll be using [k6](https://k6.io/) to run the tests, with [constant-arrival-rate executor](https://k6.io/docs/using-k6/scenarios/executors/constant-arrival-rate/) for progressive load testing, following 2 different scenarios :

- **Scenario 1** : fetch all articles, following the pagination
- **Scenario 2** : fetch all articles, calling each single article with slug, fetch associated comments for each article, and fetch profile of each related author

Duration of each scenario is 1 minute, with a 30 seconds graceful for finishing last started iterations. Results with one single test failures, i.e. any response status different from 200 or any response JSON error parsing, are not accepted.

The **Iteration creation rate** (rate / time unit) will be chosen in order to obtain the highest possible request rate, without any test failures.

### Scenario 1 - Database intensive

The interest of this scenario is to be very database intensive, by fetching all articles, authors, and favorites, following the pagination, with a couple of SQL queries. Note as each code implementation normally use eager loading to avoid N+1 queries, which can have high influence in this test.

```js
import http from "k6/http";
import { check } from "k6";

export const options = {
    scenarios: {
        articles: {
            env: { CONDUIT_URL: '<framework_url>' },
            duration: '1m',
            executor: 'constant-arrival-rate',
            rate: '<rate>',
            timeUnit: '1s',
            preAllocatedVUs: 50,
        },
    },
};

export default function () {
    const apiUrl = `https://${__ENV.CONDUIT_URL}/api`;

    const limit = 10;
    let offset = 0;

    let articles = []

    do {
        const articlesResponse = http.get(`${apiUrl}/articles?limit=${limit}&offset=${offset}`);
        check(articlesResponse, {
            "status is 200": (r) => r.status == 200,
        });

        articles = articlesResponse.json().articles;

        offset += limit;
    }
    while (articles && articles.length >= limit);
}
```

Here the expected JSON response format:

```json
{
    "articles": [
        {
            "title": "Laboriosam aliquid dolore sed dolore",
            "slug": "laboriosam-aliquid-dolore-sed-dolore",
            "description": "Rerum beatae est enim cum similique.",
            "body": "Voluptas maxime incidunt...",
            "createdAt": "2023-12-23T16:02:03.000000Z",
            "updatedAt": "2023-12-23T16:02:03.000000Z",
            "author": {
                "username": "Devin Swift III",
                "bio": "Nihil impedit totam....",
                "image": "https:\/\/randomuser.me\/api\/portraits\/men\/47.jpg",
                "following": false
            },
            "tagList": [
                "aut",
                "cumque"
            ],
            "favorited": false,
            "favoritesCount": 5
        }
    ],
    //...
    "articlesCount": 500
}
```

The expected pseudocode SQL queries to build this response:

```sql
SELECT * FROM articles LIMIT 10 OFFSET 0;
SELECT count(*) FROM articles;
SELECT * FROM users WHERE id IN (<articles.author_id...>);
SELECT * FROM article_tag WHERE article_id IN (<articles.id...>);
SELECT * FROM favorites WHERE article_id IN (<articles.id...>);
```

{{< alert >}}
It can highly differ according to each ORM, as few of them can prefer to reduce the queries by using sub select, but it's a good approximation.
{{< /alert >}}

### Scenario 2 - Runtime intensive

The interest of this scenario is to be mainly runtime intensive, by calling each endpoint of the API.

```js
import http from "k6/http";
import { check } from "k6";

export const options = {
    scenarios: {
        articles: {
            env: { CONDUIT_URL: '<framework_url>' },
            duration: '1m',
            executor: 'constant-arrival-rate',
            rate: '<rate>',
            timeUnit: '1s',
            preAllocatedVUs: 50,
        },
    },
};

export default function () {
    const apiUrl = `https://${__ENV.CONDUIT_URL}.sw.okami101.io/api`;

    const limit = 10;
    let offset = 0;

    const tagsResponse = http.get(`${apiUrl}/tags`);
    check(tagsResponse, {
        "status is 200": (r) => r.status == 200,
    });

    let articles = []

    do {
        const articlesResponse = http.get(`${apiUrl}/articles?limit=${limit}&offset=${offset}`);
        check(articlesResponse, {
            "status is 200": (r) => r.status == 200,
        });

        articles = articlesResponse.json().articles;

        for (let i = 0; i < articles.length; i++) {
            const article = articles[i];
            const articleResponse = http.get(`${apiUrl}/articles/${article.slug}`);
            check(articleResponse, {
                "status is 200": (r) => r.status == 200,
            });

            const commentsResponse = http.get(`${apiUrl}/articles/${article.slug}/comments`);
            check(commentsResponse, {
                "status is 200": (r) => r.status == 200,
            });

            const authorsResponse = http.get(`${apiUrl}/profiles/${article.author.username}`);
            check(authorsResponse, {
                "status is 200": (r) => r.status == 200,
            });
        }
        offset += limit;
    }
    while (articles && articles.length >= limit);
}
```

## The results

### Laravel (Octane)

Laravel Octane will be enabled with FrankenPHP runtime.

#### Laravel scenario 1

Iteration creation rate = **10/s**

```txt
checks.........................: 100.00% â 22287      â 0
data_received..................: 236 MB  3.7 MB/s
data_sent......................: 1.9 MB  31 kB/s
dropped_iterations.............: 164     2.570365/s
http_req_blocked...............: avg=40.43Âµs  min=272ns   med=699ns    max=64ms     p(90)=1.11Âµs   p(95)=1.29Âµs
http_req_connecting............: avg=2.37Âµs   min=0s      med=0s       max=9.31ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=129.05ms min=4.37ms  med=99.97ms  max=338.95ms p(90)=244.5ms  p(95)=254.83ms
  { expected_response:true }...: avg=129.05ms min=4.37ms  med=99.97ms  max=338.95ms p(90)=244.5ms  p(95)=254.83ms
http_req_failed................: 0.00%   â 0          â 22287
http_req_receiving.............: avg=381.18Âµs min=34.13Âµs med=297.73Âµs max=15.25ms  p(90)=588Âµs    p(95)=780.82Âµs
http_req_sending...............: avg=112.76Âµs min=36.13Âµs med=99.03Âµs  max=10.11ms  p(90)=154.25Âµs p(95)=183.11Âµs
http_req_tls_handshaking.......: avg=34.66Âµs  min=0s      med=0s       max=29.3ms   p(90)=0s       p(95)=0s
http_req_waiting...............: avg=128.55ms min=4.17ms  med=99.52ms  max=338.41ms p(90)=243.94ms p(95)=254.31ms
http_reqs......................: 22287   349.303183/s
iteration_duration.............: avg=6.62s    min=1.33s   med=6.87s    max=9.38s    p(90)=7.77s    p(95)=7.99s
iterations.....................: 437     6.849082/s
vus............................: 25      min=10       max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
        8, 273, 355, 346, 357, 345, 361, 355, 350,
      351, 335, 345, 362, 342, 356, 347, 362, 363,
      350, 359, 349, 361, 348, 350, 358, 342, 364,
      366, 346, 362, 348, 355, 360, 336, 349, 333,
      353, 348, 349, 345, 332, 367, 362, 348, 351,
      331, 351, 351, 348, 359, 353, 356, 357, 346,
      363, 346, 349, 360, 351, 359, 345, 349, 351,
      353, 205
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      10, 15, 21, 26, 32, 38, 44, 49, 50, 49, 49, 46,
      50, 48, 46, 48, 48, 49, 47, 49, 48, 49, 43, 49,
      49, 49, 50, 50, 50, 50, 48, 44, 50, 50, 50, 48,
      50, 49, 50, 48, 50, 49, 50, 50, 49, 50, 49, 49,
      47, 49, 49, 50, 50, 50, 49, 48, 48, 49, 50, 50,
      43, 40, 25
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       25,  25,  41,  56,  70,  87, 100, 116, 133, 139,
      145, 144, 134, 145, 138, 133, 136, 136, 141, 134,
      136, 138, 140, 130, 129, 136, 140, 135, 141, 134,
      135, 143, 122, 145, 143, 135, 141, 140, 144, 140,
      141, 136, 135, 146, 133, 144, 144, 139, 142, 136,
      130, 142, 138, 145, 136, 137, 142, 133, 139, 136,
      136, 139, 120,  91,  41
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.03, 0.64, 0.68,
      0.69, 0.69, 0.67, 0.68,
      0.66, 0.65, 0.68, 0.68,
      0.67, 0.68,  0.5, 0.04,
      0.04
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.15, 0.17,
      0.16, 0.16, 0.18, 0.15,
      0.18, 0.17, 0.18, 0.15,
      0.17, 0.16, 0.13, 0.03,
      0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.02, 0.08,  0.2, 0.2,
       0.2,  0.2,  0.2, 0.21, 0.2,
       0.2, 0.21,  0.2,  0.2, 0.2,
       0.1, 0.02, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.07, 0.16,
      0.15, 0.17, 0.17, 0.16,
      0.16, 0.16, 0.15, 0.16,
      0.17, 0.15, 0.16, 0.08,
      0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

We are not database limited.

#### Laravel scenario 2

Iteration creation rate = **1/s**

```txt
checks.........................: 100.00% â 53163      â 0
data_received..................: 120 MB  1.3 MB/s
data_sent......................: 4.4 MB  49 kB/s
dropped_iterations.............: 6       0.066664/s
http_req_blocked...............: avg=17.49Âµs  min=252ns   med=678ns    max=76.67ms  p(90)=1.09Âµs   p(95)=1.27Âµs
http_req_connecting............: avg=732ns    min=0s      med=0s       max=3.15ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=59.48ms  min=3.41ms  med=49.42ms  max=336.19ms p(90)=121.32ms p(95)=134.81ms
  { expected_response:true }...: avg=59.48ms  min=3.41ms  med=49.42ms  max=336.19ms p(90)=121.32ms p(95)=134.81ms
http_req_failed................: 0.00%   â 0          â 53164
http_req_receiving.............: avg=219.66Âµs min=23.57Âµs med=142.94Âµs max=15.94ms  p(90)=400.62Âµs p(95)=567.21Âµs
http_req_sending...............: avg=108.62Âµs min=31.16Âµs med=95.84Âµs  max=13.53ms  p(90)=153.78Âµs p(95)=181.93Âµs
http_req_tls_handshaking.......: avg=14.78Âµs  min=0s      med=0s       max=29.33ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=59.15ms  min=3.25ms  med=49.07ms  max=335.49ms p(90)=120.95ms p(95)=134.56ms
http_reqs......................: 53164   590.690863/s
iteration_duration.............: avg=58.57s   min=40.08s  med=1m0s     max=1m19s    p(90)=1m16s    p(95)=1m17s
iterations.....................: 9       0.099997/s
vus............................: 45      min=1        max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
        8,  83, 208, 275, 431, 479, 510, 536, 513, 589, 600,
      578, 584, 589, 616, 611, 581, 621, 597, 608, 649, 579,
      607, 594, 635, 646, 570, 622, 576, 626, 641, 607, 623,
      603, 614, 623, 602, 614, 617, 645, 628, 570, 603, 599,
      646, 632, 622, 614, 592, 591, 647, 614, 613, 623, 612,
      610, 624, 627, 613, 640, 623, 574, 584, 586, 630, 613,
      608, 634, 603, 640, 643, 616, 627, 607, 629, 631, 628,
      624, 626, 640, 622, 576, 636, 619, 647, 646, 596, 625,
      606, 634, 361
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
       1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,
      13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,
      25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,
      37, 38, 39, 40, 40, 41, 42, 42, 43, 43, 44, 45,
      46, 47, 48, 49, 50, 50, 50, 49, 50, 50, 50, 50,
      50, 50, 50, 50, 49, 49, 49, 49, 48, 48, 48, 48,
      48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 46, 46,
      46, 46, 46, 45, 45, 45
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      39, 16, 11, 12, 10, 11, 12, 14, 16, 16, 17, 19,
      21, 22, 23, 25, 28, 28, 30, 32, 31, 36, 37, 39,
      39, 39, 46, 43, 50, 47, 47, 51, 52, 53, 58, 56,
      61, 60, 62, 60, 63, 71, 68, 71, 66, 66, 71, 71,
      73, 80, 74, 78, 81, 78, 82, 82, 81, 78, 81, 79,
      80, 87, 84, 82, 82, 81, 79, 78, 80, 76, 75, 78,
      76, 79, 75, 76, 76, 76, 75, 73, 75, 81, 74, 74,
      72, 71, 75, 74, 73, 72, 71
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.15, 0.47, 0.56,
       0.6, 0.59, 0.61, 0.63,
       0.6, 0.59, 0.61, 0.58,
      0.58, 0.59, 0.59, 0.62,
      0.62, 0.65, 0.64
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.03, 0.06, 0.14, 0.17,
      0.18, 0.18, 0.19, 0.18,
       0.2, 0.21, 0.19, 0.18,
       0.2, 0.18, 0.19, 0.19,
      0.19, 0.17, 0.18
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.02, 0.13, 0.22,
      0.24, 0.26, 0.25, 0.22,
      0.25, 0.25, 0.24, 0.25,
      0.25, 0.25, 0.25, 0.25,
      0.25, 0.25, 0.25
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02,  0.1, 0.17,
      0.18, 0.18, 0.19,  0.2,
      0.19, 0.18, 0.19, 0.19,
      0.19, 0.19, 0.17,  0.2,
      0.19, 0.19, 0.19
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

This is where Laravel Octane really shines, previously we had less than 300 req/s with Apache.

### Symfony (FrankenPHP)

#### Symfony scenario 1

Iteration creation rate = **10/s**

```txt
checks.........................: 100.00% â 21930      â 0
data_received..................: 198 MB  3.1 MB/s
data_sent......................: 1.9 MB  30 kB/s
dropped_iterations.............: 171     2.679253/s
http_req_blocked...............: avg=40.29Âµs  min=266ns   med=720ns    max=65.15ms  p(90)=1.15Âµs   p(95)=1.34Âµs
http_req_connecting............: avg=2.38Âµs   min=0s      med=0s       max=6.02ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=130.84ms min=7.15ms  med=85.37ms  max=337.78ms p(90)=242.21ms p(95)=252.98ms
  { expected_response:true }...: avg=130.84ms min=7.15ms  med=85.37ms  max=337.78ms p(90)=242.21ms p(95)=252.98ms
http_req_failed................: 0.00%   â 0          â 21930
http_req_receiving.............: avg=428.79Âµs min=28.72Âµs med=294.3Âµs  max=26.69ms  p(90)=717.72Âµs p(95)=1.05ms
http_req_sending...............: avg=116.86Âµs min=34.94Âµs med=100.46Âµs max=16.13ms  p(90)=157.81Âµs p(95)=185.95Âµs
http_req_tls_handshaking.......: avg=34.42Âµs  min=0s      med=0s       max=29.11ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=130.3ms  min=6.88ms  med=84.81ms  max=337.45ms p(90)=241.7ms  p(95)=252.54ms
http_reqs......................: 21930   343.602476/s
iteration_duration.............: avg=6.7s     min=1.41s   med=7.02s    max=9.09s    p(90)=7.96s    p(95)=8.17s
iterations.....................: 430     6.737303/s
vus............................: 22      min=10       max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
       75, 346, 355, 351, 351, 331, 347, 356, 349,
      355, 327, 343, 338, 352, 349, 326, 356, 349,
      350, 354, 327, 350, 345, 347, 341, 329, 352,
      351, 352, 353, 331, 357, 355, 350, 351, 314,
      350, 355, 351, 357, 330, 354, 355, 350, 353,
      323, 351, 346, 344, 356, 323, 355, 343, 351,
      355, 322, 354, 353, 336, 354, 328, 352, 354,
      346,  64
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      10, 16, 21, 26, 33, 39, 43, 50, 48, 49, 49, 50,
      50, 48, 49, 48, 50, 49, 50, 49, 50, 50, 49, 50,
      49, 49, 50, 50, 47, 49, 50, 49, 50, 50, 50, 49,
      47, 48, 46, 50, 50, 50, 50, 47, 48, 49, 50, 50,
      49, 50, 49, 49, 48, 49, 47, 49, 49, 50, 46, 49,
      38, 31, 22
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       24,  31,  46,  61,  76,  98, 107, 120, 139, 136,
      146, 150, 145, 139, 136, 151, 140, 140, 141, 137,
      146, 143, 140, 140, 144, 149, 140, 140, 138, 132,
      149, 137, 139, 141, 140, 156, 142, 135, 136, 131,
      149, 141, 139, 142, 132, 150, 140, 144, 143, 138,
      154, 139, 141, 139, 138, 151, 140, 141, 145, 136,
      144, 113,  89,  60,  22
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.04, 0.11, 0.39, 0.39,
      0.36, 0.35, 0.35, 0.37,
      0.34, 0.34, 0.32, 0.34,
      0.33, 0.35, 0.18, 0.03,
      0.04, 0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.04, 0.08, 0.09,
       0.1, 0.08, 0.09, 0.08,
       0.1, 0.09, 0.11, 0.08,
      0.09, 0.08, 0.05, 0.03,
      0.03, 0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.02, 0.51, 0.91,
      0.91, 0.92, 0.91,  0.9,
      0.92, 0.91, 0.92, 0.92,
      0.91, 0.92, 0.92, 0.15,
      0.02, 0.02, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.05, 0.08,
      0.08, 0.08, 0.08, 0.09,
      0.08, 0.08, 0.08, 0.08,
      0.08, 0.08, 0.08, 0.03,
      0.02, 0.02, 0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

We are database limited, performing same as Laravel.

#### Symfony scenario 2

Iteration creation rate = **2/s**

```txt
checks.........................: 100.00% â 110192      â 0
data_received..................: 195 MB  2.3 MB/s
data_sent......................: 8.7 MB  105 kB/s
dropped_iterations.............: 49      0.588079/s
http_req_blocked...............: avg=9.46Âµs   min=237ns   med=582ns    max=59.73ms  p(90)=890ns    p(95)=1.03Âµs
http_req_connecting............: avg=378ns    min=0s      med=0s       max=3.44ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=27.36ms  min=2.09ms  med=22.91ms  max=534.89ms p(90)=53.87ms  p(95)=61.96ms
  { expected_response:true }...: avg=27.36ms  min=2.09ms  med=22.91ms  max=534.89ms p(90)=53.87ms  p(95)=61.96ms
http_req_failed................: 0.00%   â 0           â 110192
http_req_receiving.............: avg=393.34Âµs min=20.27Âµs med=169.55Âµs max=44.39ms  p(90)=667.69Âµs p(95)=1.17ms
http_req_sending...............: avg=96.96Âµs  min=21.03Âµs med=82.98Âµs  max=11.97ms  p(90)=133.54Âµs p(95)=160.59Âµs
http_req_tls_handshaking.......: avg=8.02Âµs   min=0s      med=0s       max=58.6ms   p(90)=0s       p(95)=0s
http_req_waiting...............: avg=26.87ms  min=1.57ms  med=22.42ms  max=534.69ms p(90)=53.21ms  p(95)=61.26ms
http_reqs......................: 110192  1322.481752/s
iteration_duration.............: avg=42.8s    min=19.32s  med=46.97s   max=53.14s   p(90)=51.96s   p(95)=52.6s
iterations.....................: 71      0.852115/s
vus............................: 2       min=2         max=50
vus_max........................: 50      min=50        max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
       162,  449,  974, 1254, 1075, 1260, 1289, 1267, 1306,
      1347, 1403, 1335, 1225, 1431, 1295, 1330, 1365, 1344,
      1461, 1369, 1461, 1398, 1310, 1460, 1412, 1433, 1475,
      1373, 1393, 1342, 1481, 1446, 1364, 1386, 1359, 1353,
      1368, 1316, 1386, 1258, 1451, 1502, 1327, 1419, 1327,
      1339, 1389, 1373, 1388, 1361, 1494, 1454, 1337, 1420,
      1374, 1440, 1408, 1319, 1484, 1370, 1433, 1329, 1334,
      1393, 1415, 1347, 1399, 1412, 1320, 1290, 1508, 1401,
      1312, 1454, 1315, 1347, 1452, 1221, 1262, 1221, 1259,
      1306,  676,   95
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
       2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24,
      26, 28, 30, 32, 34, 36, 38, 39, 41, 41, 43, 45,
      46, 48, 49, 50, 50, 50, 49, 50, 50, 50, 49, 50,
      50, 50, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      49, 50, 48, 50, 48, 50, 50, 50, 49, 50, 50, 50,
      49, 46, 44, 44, 43, 42, 40, 39, 36, 36, 33, 30,
      27, 24, 22, 17, 14, 14, 13, 12,  9,  7,  2
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       9,  8,  5,  6,  8,  9, 10, 12, 13, 14, 15, 17,
      21, 19, 22, 23, 25, 26, 25, 28, 28, 28, 34, 30,
      32, 33, 30, 39, 36, 34, 36, 34, 37, 36, 35, 34,
      40, 38, 35, 39, 35, 33, 37, 35, 36, 38, 36, 36,
      35, 37, 33, 34, 37, 35, 36, 34, 35, 38, 33, 36,
      35, 34, 35, 32, 30, 32, 29, 28, 28, 27, 24, 23,
      20, 19, 17, 15, 11, 11, 11, 10,  8,  6,  5,  5
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03,  0.4,  0.6, 0.61,
      0.61, 0.64, 0.67, 0.68,
      0.64, 0.66, 0.65,  0.7,
      0.66, 0.66, 0.65, 0.67,
      0.58, 0.34, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.14, 0.17, 0.17,
      0.19, 0.17, 0.19, 0.19,
      0.19, 0.21, 0.19, 0.18,
      0.18, 0.18, 0.18, 0.18,
      0.16, 0.11, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.06, 0.31, 0.33,
      0.32, 0.35, 0.34, 0.35,
      0.33, 0.34, 0.34, 0.34,
      0.34, 0.34, 0.34, 0.34,
      0.33, 0.32,  0.1
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.03,  0.1, 0.13,
      0.11, 0.13, 0.13, 0.12,
      0.13, 0.13, 0.12, 0.13,
      0.13, 0.12, 0.12, 0.12,
      0.13, 0.12, 0.05
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

Huge gap in performance against Laravel Octane here, about twice better ! Without FrankenPHP, we were capping to previously about 300 req/s on Apache...

### FastAPI

As a side note here, uvicorn is limited to 1 CPU core, so I use 2 replicas on each worker to use all CPU cores.

#### FastAPI scenario 1

Iteration creation rate =  **15/s**

```txt
checks.........................: 100.00% â 29835      â 0
data_received..................: 241 MB  3.9 MB/s
data_sent......................: 2.6 MB  42 kB/s
dropped_iterations.............: 315     5.03316/s
http_req_blocked...............: avg=30.38Âµs  min=227ns   med=651ns    max=52.06ms  p(90)=1.02Âµs   p(95)=1.18Âµs
http_req_connecting............: avg=1.98Âµs   min=0s      med=0s       max=5.76ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=97.85ms  min=6.31ms  med=83.03ms  max=500.66ms p(90)=192.52ms p(95)=226.66ms
  { expected_response:true }...: avg=97.85ms  min=6.31ms  med=83.03ms  max=500.66ms p(90)=192.52ms p(95)=226.66ms
http_req_failed................: 0.00%   â 0          â 29835
http_req_receiving.............: avg=570.36Âµs min=28.53Âµs med=260.32Âµs max=21.18ms  p(90)=1.23ms   p(95)=1.94ms
http_req_sending...............: avg=112.03Âµs min=32.86Âµs med=95.56Âµs  max=16.17ms  p(90)=150.61Âµs p(95)=181.13Âµs
http_req_tls_handshaking.......: avg=26.39Âµs  min=0s      med=0s       max=31.75ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=97.17ms  min=6.14ms  med=82.29ms  max=497.14ms p(90)=191.78ms p(95)=225.93ms
http_reqs......................: 29835   476.712194/s
iteration_duration.............: avg=5.02s    min=1.44s   med=5.12s    max=6.71s    p(90)=5.77s    p(95)=6s
iterations.....................: 585     9.347298/s
vus............................: 21      min=15       max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
      345, 451, 480, 469, 476, 507, 461, 476, 523,
      494, 467, 493, 476, 501, 483, 502, 456, 467,
      502, 465, 480, 476, 460, 488, 513, 507, 449,
      477, 467, 488, 496, 461, 467, 468, 508, 515,
      444, 470, 496, 495, 496, 490, 453, 513, 491,
      481, 441, 471, 520, 463, 495, 457, 484, 454,
      475, 467, 462, 479, 459, 481, 504, 470, 210
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      15, 25, 34, 46, 49, 50, 50, 49, 46, 50, 49, 50,
      50, 47, 49, 50, 50, 50, 50, 50, 50, 50, 50, 49,
      49, 50, 50, 49, 50, 50, 48, 50, 50, 49, 49, 50,
      50, 49, 48, 50, 49, 49, 49, 50, 49, 50, 50, 50,
      49, 48, 50, 49, 50, 50, 50, 49, 49, 50, 50, 50,
      37, 21
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       24,  48,  62,  83, 104,  97, 104, 101,  93,  99, 103,
      100, 102,  91, 109,  99, 108, 104,  96, 102, 105, 106,
      105, 102,  99,  93, 110, 104, 104, 100,  98, 107, 106,
      106,  96,  96, 103, 108,  96,  99, 102,  98, 108,  93,
      104,  99, 110, 100, 101, 102, 101, 104, 107, 105, 107,
      105, 102, 105, 103, 103,  85,  66,  29
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.48, 0.71,  0.7,
       0.7, 0.67, 0.69, 0.68,
       0.7, 0.69,  0.7, 0.68,
      0.69,  0.5, 0.03, 0.03,
      0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.14,  0.2, 0.19,
      0.19, 0.19, 0.19, 0.19,
      0.19, 0.19,  0.2,  0.2,
      0.19, 0.13, 0.02, 0.02,
      0.03, 0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.05, 0.36,  0.4,
      0.41,  0.4, 0.41, 0.38,
      0.42, 0.41, 0.42, 0.37,
       0.4, 0.39, 0.16, 0.02,
      0.02, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.04, 0.25,  0.3,
      0.29,  0.3, 0.31, 0.32,
      0.33, 0.32, 0.37, 0.26,
       0.3, 0.31, 0.11, 0.02,
      0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

FastAPI outperforms above PHP frameworks in this specific scenario, and database isn't the bottleneck anymore.

#### FastAPI scenario 2

Iteration creation rate = **2/s**

```txt
checks.........................: 100.00% â 64223      â 0
data_received..................: 128 MB  1.4 MB/s
data_sent......................: 4.8 MB  53 kB/s
dropped_iterations.............: 71      0.788854/s
http_req_blocked...............: avg=16.09Âµs  min=242ns   med=634ns    max=71.12ms  p(90)=1Âµs      p(95)=1.18Âµs
http_req_connecting............: avg=936ns    min=0s      med=0s       max=11.27ms  p(90)=0s       p(95)=0s
http_req_duration..............: avg=58.19ms  min=4.23ms  med=33.6ms   max=430.25ms p(90)=146.63ms p(95)=177.64ms
  { expected_response:true }...: avg=58.19ms  min=4.23ms  med=33.6ms   max=430.25ms p(90)=146.63ms p(95)=177.64ms
http_req_failed................: 0.00%   â 0          â 64223
http_req_receiving.............: avg=224.16Âµs min=20.82Âµs med=120.98Âµs max=11.92ms  p(90)=456.57Âµs p(95)=713.27Âµs
http_req_sending...............: avg=98.3Âµs   min=28.53Âµs med=85.53Âµs  max=15.47ms  p(90)=136.99Âµs p(95)=162.39Âµs
http_req_tls_handshaking.......: avg=13.73Âµs  min=0s      med=0s       max=44.98ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=57.87ms  min=4.04ms  med=33.29ms  max=429.5ms  p(90)=146.17ms p(95)=177.16ms
http_reqs......................: 64223   713.557494/s
iteration_duration.............: avg=1m15s    min=1m6s    med=1m15s    max=1m23s    p(90)=1m23s    p(95)=1m23s
iterations.....................: 11      0.122217/s
vus............................: 39      min=2        max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
       45, 176, 457, 647, 698, 657, 670, 671, 738, 801, 676,
      783, 692, 700, 760, 688, 743, 676, 698, 740, 695, 726,
      763, 759, 723, 684, 774, 731, 740, 778, 685, 792, 746,
      755, 733, 682, 753, 730, 763, 735, 707, 792, 744, 695,
      764, 679, 778, 692, 775, 715, 675, 774, 712, 714, 742,
      699, 719, 684, 762, 789, 681, 752, 646, 722, 769, 651,
      778, 743, 692, 764, 701, 736, 719, 816, 768, 707, 765,
      735, 762, 725, 701, 714, 652, 769, 784, 713, 703, 735,
      767, 754, 225
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
       2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24,
      26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 49, 48, 48, 47, 47,
      46, 46, 46, 45, 45, 44, 44, 44, 43, 43, 43, 43,
      42, 42, 41, 41, 39, 39
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      17, 16, 10, 10, 12, 16, 18, 22, 23, 23, 30, 30,
      34, 39, 38, 44, 44, 52, 52, 52, 58, 60, 57, 62,
      65, 72, 64, 68, 69, 65, 73, 62, 63, 71, 67, 74,
      67, 68, 65, 67, 72, 63, 66, 72, 65, 72, 66, 71,
      65, 67, 72, 68, 70, 69, 68, 69, 72, 72, 65, 64,
      72, 68, 76, 69, 65, 74, 66, 65, 72, 60, 69, 64,
      65, 57, 59, 65, 56, 63, 56, 59, 64, 59, 67, 56,
      53, 60, 58, 53, 56, 51, 47
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.18, 0.58, 0.63,
      0.65, 0.67, 0.66, 0.68,
      0.63, 0.67, 0.67, 0.66,
      0.66, 0.68, 0.69, 0.65,
      0.69, 0.66, 0.64
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.03, 0.05, 0.17,  0.2,
      0.19, 0.19, 0.21,  0.2,
      0.21, 0.19, 0.19, 0.21,
      0.21, 0.21,  0.2, 0.19,
      0.21, 0.19,  0.2
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.02, 0.14, 0.21,
      0.21, 0.24, 0.27, 0.25,
      0.26, 0.26, 0.26, 0.26,
      0.26, 0.25, 0.25, 0.26,
      0.26, 0.26, 0.22
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.03, 0.08, 0.14,
      0.19, 0.22, 0.28, 0.23,
      0.25, 0.22, 0.26, 0.28,
      0.26, 0.24, 0.28, 0.26,
      0.25, 0.24, 0.25
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

FastAPI fall behind Symfony but ahead of Laravel.

### NestJS

Note that we're using **Fastify** adapter instead of Express in order to maximize performance.

#### NestJS scenario 1

```txt
checks.........................: 100.00% â 46104      â 0
data_received..................: 791 MB  13 MB/s
data_sent......................: 4.4 MB  72 kB/s
dropped_iterations.............: 296     4.79183/s
http_req_blocked...............: avg=22.48Âµs  min=250ns    med=610ns    max=56.72ms  p(90)=954ns    p(95)=1.1Âµs
http_req_connecting............: avg=1.12Âµs   min=0s       med=0s       max=6.32ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=62.1ms   min=2.94ms   med=52.66ms  max=322.4ms  p(90)=115.17ms p(95)=120.56ms
  { expected_response:true }...: avg=62.1ms   min=2.94ms   med=52.66ms  max=322.4ms  p(90)=115.17ms p(95)=120.56ms
http_req_failed................: 0.00%   â 0          â 46104
http_req_receiving.............: avg=388.24Âµs min=25.63Âµs  med=233.32Âµs max=205.79ms p(90)=555.24Âµs p(95)=925.96Âµs
http_req_sending...............: avg=119.09Âµs min=29.63Âµs  med=92.44Âµs  max=41.89ms  p(90)=148.13Âµs p(95)=183.72Âµs
http_req_tls_handshaking.......: avg=20Âµs     min=0s       med=0s       max=55.7ms   p(90)=0s       p(95)=0s
http_req_waiting...............: avg=61.59ms  min=0s       med=52.07ms  max=171.12ms p(90)=114.69ms p(95)=119.96ms
http_reqs......................: 46104   746.359903/s
iteration_duration.............: avg=3.21s    min=966.59ms med=3.26s    max=4.4s     p(90)=3.7s     p(95)=3.83s
iterations.....................: 904     14.634508/s
vus............................: 31      min=20       max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
      209, 657, 702, 731, 710, 709, 685, 759, 770,
      744, 743, 767, 751, 750, 755, 755, 738, 771,
      764, 735, 751, 725, 750, 759, 750, 762, 733,
      758, 778, 755, 739, 745, 787, 767, 755, 765,
      736, 790, 786, 760, 754, 745, 776, 781, 766,
      768, 698, 791, 755, 744, 749, 741, 790, 762,
      775, 781, 756, 752, 769, 753, 724, 714, 104
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      20, 30, 42, 50, 49, 50, 49, 49, 50, 49, 49, 50,
      50, 49, 49, 50, 45, 50, 50, 49, 47, 50, 49, 46,
      46, 50, 50, 48, 46, 50, 50, 48, 49, 47, 48, 50,
      50, 47, 49, 49, 49, 48, 49, 49, 45, 50, 49, 49,
      49, 49, 50, 50, 49, 49, 47, 49, 47, 49, 48, 49,
      31
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      15, 27, 42, 57, 68, 68, 69, 65, 63, 65, 65, 60,
      66, 65, 65, 64, 63, 62, 63, 67, 65, 63, 66, 65,
      64, 62, 65, 66, 60, 64, 66, 64, 61, 63, 65, 63,
      65, 62, 60, 65, 64, 62, 63, 63, 64, 59, 67, 63,
      63, 64, 65, 64, 63, 64, 63, 59, 62, 64, 63, 64,
      62, 39, 14
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.14, 0.53, 0.49,
       0.5, 0.49, 0.49, 0.48,
       0.5, 0.49,  0.5,  0.5,
      0.49, 0.49, 0.05, 0.03,
      0.04, 0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.03, 0.07, 0.22, 0.23,
      0.23, 0.23, 0.23, 0.23,
      0.22, 0.23, 0.22, 0.21,
      0.24, 0.21, 0.02, 0.02,
      0.03, 0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.02, 0.15, 0.24,
      0.26, 0.26, 0.25, 0.25,
      0.28, 0.26, 0.25, 0.24,
      0.25, 0.28,  0.2, 0.02,
      0.02, 0.02, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.14, 0.25,
      0.25, 0.24, 0.25, 0.26,
      0.24, 0.25, 0.26, 0.26,
      0.26, 0.25, 0.18, 0.02,
      0.02, 0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

Far ahead of FastAPI, let's keep up on scenario 2.

#### NestJS scenario 2

Iteration creation rate = **3/s**

```txt
checks.........................: 100.00% â 141232      â 0
data_received..................: 651 MB  7.4 MB/s
data_sent......................: 12 MB   131 kB/s
dropped_iterations.............: 89      1.010713/s
http_req_blocked...............: avg=7.74Âµs   min=200ns   med=577ns   max=64.13ms  p(90)=896ns    p(95)=1.04Âµs
http_req_connecting............: avg=335ns    min=0s      med=0s      max=6.16ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=24.88ms  min=1.94ms  med=20.22ms max=300.63ms p(90)=49.61ms  p(95)=62.06ms
  { expected_response:true }...: avg=24.88ms  min=1.94ms  med=20.22ms max=300.63ms p(90)=49.61ms  p(95)=62.06ms
http_req_failed................: 0.00%   â 0           â 141232
http_req_receiving.............: avg=415.42Âµs min=20.02Âµs med=172.2Âµs max=210.76ms p(90)=753.01Âµs p(95)=1.3ms
http_req_sending...............: avg=94.98Âµs  min=21.16Âµs med=78.33Âµs max=25.47ms  p(90)=129.63Âµs p(95)=158.24Âµs
http_req_tls_handshaking.......: avg=6.32Âµs   min=0s      med=0s      max=32.94ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=24.37ms  min=0s      med=19.73ms max=295.3ms  p(90)=48.93ms  p(95)=61.29ms
http_reqs......................: 141232  1603.877186/s
iteration_duration.............: avg=38.96s   min=27.77s  med=40.36s  max=47s      p(90)=45.89s   p(95)=46.29s
iterations.....................: 91      1.033426/s
vus............................: 3       min=3         max=50
vus_max........................: 50      min=50        max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
        18,  297,  824, 1140, 1286, 1523, 1425, 1587, 1485,
      1517, 1692, 1669, 1610, 1651, 1677, 1725, 1693, 1590,
      1501, 1574, 1592, 1775, 1535, 1640, 1710, 1633, 1699,
      1524, 1680, 1653, 1787, 1752, 1658, 1680, 1655, 1754,
      1763, 1669, 1567, 1616, 1758, 1600, 1637, 1609, 1740,
      1810, 1660, 1567, 1721, 1510, 1771, 1786, 1631, 1634,
      1671, 1767, 1754, 1649, 1682, 1500, 1708, 1676, 1687,
      1641, 1572, 1707, 1667, 1534, 1546, 1571, 1711, 1618,
      1670, 1703, 1613, 1784, 1677, 1713, 1672, 1679, 1716,
      1698, 1369, 1662, 1637, 1746, 1629, 1491,  852
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
       3,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33, 36,
      39, 42, 45, 48, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 49, 50, 49, 50, 49, 50, 50, 49, 50,
      50, 49, 50, 50, 49, 50, 49, 50, 49, 49, 49, 50,
      49, 50, 50, 50, 49, 49, 50, 49, 47, 48, 49, 50,
      47, 42, 41, 41, 41, 41, 41, 41, 41, 41, 41, 40,
      40, 38, 36, 35, 34, 33, 32, 31, 30, 29, 27, 24,
      21, 17, 12,  3
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      11,  9,  6,  8,  9, 10, 12, 13, 16, 17, 17, 20,
      22, 23, 25, 26, 28, 31, 34, 32, 31, 28, 32, 30,
      29, 30, 29, 33, 29, 30, 28, 28, 30, 30, 30, 28,
      28, 30, 31, 30, 28, 31, 30, 31, 28, 28, 30, 31,
      29, 33, 28, 28, 30, 30, 29, 28, 28, 29, 29, 32,
      30, 28, 26, 25, 25, 24, 24, 27, 26, 26, 24, 25,
      24, 23, 23, 20, 21, 20, 20, 19, 18, 18, 21, 16,
      15, 12, 11,  9,  6
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.28, 0.48, 0.49,
      0.48, 0.48, 0.48,  0.5,
      0.49, 0.48, 0.48, 0.48,
      0.48,  0.5, 0.49,  0.5,
      0.49, 0.48, 0.35
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.11, 0.21, 0.22,
      0.23, 0.24, 0.23, 0.23,
      0.23, 0.25, 0.23, 0.24,
      0.24, 0.21, 0.23, 0.23,
      0.24, 0.22, 0.17
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.03, 0.25, 0.32,
      0.32, 0.33, 0.33, 0.34,
      0.35, 0.35, 0.34, 0.34,
      0.34, 0.34, 0.33, 0.33,
      0.34, 0.35, 0.33
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.16, 0.19,
      0.24, 0.21, 0.23, 0.23,
      0.22, 0.22, 0.24, 0.23,
      0.24, 0.23, 0.22, 0.21,
      0.24, 0.24, 0.21
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

Now NestJS exceeds the performance of Symfony and FrankenPHP. The native even loop system is very efficient. Note as it's configured to use Fastify under the hood instead of Express. With Express it match 1200 req/s, so Fastify really shines here. It's time to test it against compiled language.

### Spring Boot

#### Spring Boot scenario 1

Iteration creation rate = **40/s**

```txt
checks.........................: 100.00% â 95676       â 0
data_received..................: 1.8 GB  30 MB/s
data_sent......................: 8.2 MB  135 kB/s
dropped_iterations.............: 525     8.61974/s
http_req_blocked...............: avg=13.02Âµs min=197ns    med=519ns    max=66.13ms  p(90)=752ns    p(95)=866ns
http_req_connecting............: avg=940ns   min=0s       med=0s       max=7.96ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=29.35ms min=2.59ms   med=26.27ms  max=184.74ms p(90)=49.8ms   p(95)=59.97ms
  { expected_response:true }...: avg=29.35ms min=2.59ms   med=26.27ms  max=184.74ms p(90)=49.8ms   p(95)=59.97ms
http_req_failed................: 0.00%   â 0           â 95676
http_req_receiving.............: avg=2.31ms  min=24.31Âµs  med=991.85Âµs max=87.57ms  p(90)=5.43ms   p(95)=9.12ms
http_req_sending...............: avg=186.7Âµs min=24.8Âµs   med=81.4Âµs   max=56.81ms  p(90)=159.29Âµs p(95)=243.03Âµs
http_req_tls_handshaking.......: avg=10.78Âµs min=0s       med=0s       max=54.77ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=26.85ms min=0s       med=23.8ms   max=180.66ms p(90)=46.18ms  p(95)=55.49ms
http_reqs......................: 95676   1570.861508/s
iteration_duration.............: avg=1.55s   min=775.41ms med=1.56s    max=2.12s    p(90)=1.71s    p(95)=1.76s
iterations.....................: 1876    30.801206/s
vus............................: 49      min=33        max=50
vus_max........................: 50      min=50        max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
        48, 1270, 1532, 1558, 1625, 1613, 1419,
      1497, 1628, 1514, 1605, 1489, 1575, 1653,
      1590, 1640, 1483, 1568, 1638, 1623, 1629,
      1524, 1641, 1517, 1616, 1592, 1525, 1613,
      1712, 1674, 1598, 1531, 1554, 1584, 1616,
      1606, 1457, 1539, 1606, 1568, 1606, 1532,
      1533, 1664, 1601, 1574, 1483, 1591, 1665,
      1662, 1590, 1537, 1585, 1624, 1603, 1585,
      1514, 1552, 1681, 1592, 1645,  987
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      33, 50, 49, 49, 50, 49, 50, 50, 50, 48, 50, 49,
      49, 49, 48, 49, 50, 49, 46, 49, 47, 50, 50, 48,
      50, 48, 49, 45, 50, 50, 48, 49, 49, 49, 49, 50,
      49, 50, 49, 50, 50, 50, 48, 47, 46, 49, 48, 49,
      48, 50, 48, 49, 50, 48, 50, 49, 46, 48, 49, 49
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      11, 19, 28, 31, 29, 28, 33, 31, 29, 30, 30, 32,
      30, 29, 29, 29, 32, 30, 29, 29, 29, 31, 28, 32,
      29, 29, 29, 28, 27, 28, 29, 31, 30, 30, 29, 30,
      31, 30, 30, 30, 29, 31, 30, 29, 29, 29, 31, 30,
      28, 28, 30, 31, 30, 29, 30, 29, 31, 30, 28, 30,
      29, 21
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.26, 0.35, 0.32,
      0.32, 0.34, 0.32, 0.32,
      0.32, 0.34, 0.32, 0.33,
      0.33, 0.25, 0.04, 0.03,
      0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.03, 0.13, 0.32, 0.32,
      0.32, 0.31, 0.33, 0.31,
      0.32,  0.3, 0.32, 0.33,
      0.32, 0.26, 0.02, 0.02,
      0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.02, 0.39, 0.59,
      0.59, 0.61, 0.61, 0.61,
       0.6,  0.6, 0.59, 0.59,
      0.57,  0.6, 0.29, 0.02,
      0.03, 0.02, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.03, 0.23, 0.35,
      0.37, 0.36, 0.35, 0.34,
      0.34, 0.36, 0.38, 0.37,
      0.39, 0.36, 0.16, 0.02,
      0.02, 0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

End of debate, Spring Boot destroys competition for 1st scenario. Moreover, database is the bottleneck, and java runtime is clearly sleeping here. But JPA Hibernate was difficult to tune for optimal performance, and finally the magic [`@BatchSize`](https://docs.jboss.org/hibernate/orm/current/javadocs/org/hibernate/annotations/BatchSize.html) annotation was the key, allowing to merge n+1 queries into 1+1 queries. Without it, Spring Boot was performing 3 times slower !

#### Spring Boot scenario 2

Iteration creation rate = **10/s**

```txt
checks.........................: 100.00% â 173824      â 0
data_received..................: 774 MB  11 MB/s
data_sent......................: 15 MB   215 kB/s
dropped_iterations.............: 489     6.809786/s
http_req_blocked...............: avg=7.54Âµs   min=212ns   med=529ns   max=52.17ms  p(90)=742ns    p(95)=852ns
http_req_connecting............: avg=292ns    min=0s      med=0s      max=4.99ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=17.72ms  min=1.88ms  med=14.67ms max=246.82ms p(90)=33.14ms  p(95)=41.12ms
  { expected_response:true }...: avg=17.72ms  min=1.88ms  med=14.67ms max=246.82ms p(90)=33.14ms  p(95)=41.12ms
http_req_failed................: 0.00%   â 0           â 173824
http_req_receiving.............: avg=2.56ms   min=23.95Âµs med=1.45ms  max=58.29ms  p(90)=6.13ms   p(95)=8.97ms
http_req_sending...............: avg=102.03Âµs min=22.45Âµs med=76.81Âµs max=42.01ms  p(90)=127.42Âµs p(95)=163.59Âµs
http_req_tls_handshaking.......: avg=6.34Âµs   min=0s      med=0s      max=50.96ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=15.06ms  min=0s      med=12ms    max=244.1ms  p(90)=29.02ms  p(95)=36.66ms
http_reqs......................: 173824  2420.663008/s
iteration_duration.............: avg=27.87s   min=12s     med=29.74s  max=31.63s   p(90)=30.76s   p(95)=31.06s
iterations.....................: 112     1.559706/s
vus............................: 12      min=10        max=50
vus_max........................: 50      min=50        max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
       419, 1778, 2087, 2261, 2215, 2426, 2458, 2483,
      2402, 2500, 2525, 2763, 2426, 2634, 2587, 2568,
      2740, 2495, 2510, 2458, 2533, 2615, 2392, 2553,
      2577, 2566, 2756, 2424, 2489, 2428, 2515, 2690,
      2526, 2512, 2500, 2511, 2658, 2473, 2468, 2473,
      2593, 2633, 2481, 2558, 2527, 2491, 2672, 2613,
      2447, 2417, 2479, 2589, 2492, 2500, 2558, 2544,
      2604, 2557, 2593, 2452, 2635, 2598, 2361, 2414,
      2066, 2025, 1951, 1988, 1869, 1881, 2023, 1734,
        85
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      10, 20, 30, 40, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 49, 50, 48, 49, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      45, 40, 33, 21, 12, 12, 12, 12, 12, 12, 12
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       6,  7, 10, 14, 19, 20, 20, 20, 20, 20, 20, 18,
      20, 19, 19, 19, 18, 20, 20, 20, 20, 19, 21, 19,
      19, 20, 18, 20, 20, 20, 20, 18, 19, 19, 19, 20,
      18, 20, 20, 20, 19, 19, 20, 19, 19, 20, 18, 19,
      20, 20, 20, 19, 20, 20, 19, 20, 19, 19, 19, 20,
      19, 17, 16, 13,  9,  6,  6,  6,  6,  6,  6,  5,
       3
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.51,  0.5, 0.37,
      0.39, 0.39, 0.36, 0.37,
      0.37, 0.38, 0.39, 0.36,
      0.38, 0.37, 0.27, 0.13,
      0.04, 0.03, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.27, 0.37, 0.36,
      0.34, 0.35, 0.36, 0.35,
      0.36, 0.35, 0.35, 0.34,
      0.35, 0.34, 0.26, 0.12,
      0.03, 0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.07, 0.42, 0.47,
       0.5,  0.5, 0.49, 0.48,
      0.48, 0.48, 0.49, 0.51,
      0.51, 0.51, 0.44, 0.37,
      0.06, 0.02, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.03, 0.05, 0.29, 0.33,
      0.33, 0.32, 0.34, 0.33,
      0.34, 0.34, 0.33, 0.31,
      0.32, 0.31, 0.28, 0.25,
      0.04, 0.02, 0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

Java is maybe not the best DX experience for me, but it's a beast in terms of raw performance. Besides, we'll again have database bottleneck, which is the only case seen in this scenario on every framework tested ! Impossible to reach 100% java runtime CPU usage, even with 4 CPU cores, staying only at 60-70% overall...

### ASP.NET Core

#### ASP.NET Core scenario 1

Iteration creation rate = **20/s**

```txt
checks.........................: 100.00% â 55590     â 0
data_received..................: 1.3 GB  21 MB/s
data_sent......................: 5.1 MB  83 kB/s
dropped_iterations.............: 110     1.793989/s
http_req_blocked...............: avg=17.61Âµs min=206ns    med=575ns    max=65.29ms  p(90)=888ns    p(95)=1.03Âµs
http_req_connecting............: avg=806ns   min=0s       med=0s       max=3.77ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=48.38ms min=2.81ms   med=43.08ms  max=286.36ms p(90)=94.36ms  p(95)=110.84ms
  { expected_response:true }...: avg=48.38ms min=2.81ms   med=43.08ms  max=286.36ms p(90)=94.36ms  p(95)=110.84ms
http_req_failed................: 0.00%   â 0         â 55590
http_req_receiving.............: avg=1.46ms  min=22.08Âµs  med=596.35Âµs max=51.59ms  p(90)=3.1ms    p(95)=5.66ms
http_req_sending...............: avg=141.6Âµs min=29.36Âµs  med=88.9Âµs   max=36.89ms  p(90)=156.02Âµs p(95)=214.06Âµs
http_req_tls_handshaking.......: avg=15.21Âµs min=0s       med=0s       max=34.23ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=46.77ms min=0s       med=41.21ms  max=280.31ms p(90)=92.33ms  p(95)=108.67ms
http_reqs......................: 55590   906.61695/s
iteration_duration.............: avg=2.52s   min=647.26ms med=2.6s     max=3.5s     p(90)=2.97s    p(95)=3.05s
iterations.....................: 1090    17.776803/s
vus............................: 19      min=14      max=50
vus_max........................: 50      min=50      max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
      275, 849, 897, 867, 871, 966, 947, 937, 863,
      897, 905, 921, 908, 835, 914, 936, 927, 915,
      866, 924, 921, 928, 927, 875, 925, 933, 901,
      915, 874, 923, 943, 931, 933, 841, 884, 948,
      929, 939, 886, 925, 947, 938, 938, 841, 912,
      929, 935, 925, 895, 951, 927, 932, 917, 857,
      901, 926, 914, 928, 882, 912, 955, 627
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      14, 22, 26, 30, 36, 38, 43, 46, 50, 47, 46, 48,
      48, 46, 46, 49, 50, 48, 47, 49, 47, 47, 50, 49,
      48, 48, 47, 50, 47, 41, 46, 49, 48, 47, 49, 48,
      44, 44, 45, 50, 48, 44, 46, 50, 49, 46, 49, 48,
      47, 48, 47, 47, 49, 49, 48, 48, 47, 46, 49, 50,
      19
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
      11, 17, 23, 30, 35, 37, 40, 44, 53, 53, 53, 50,
      51, 58, 51, 50, 52, 51, 53, 52, 52, 50, 52, 55,
      51, 51, 50, 50, 55, 49, 45, 49, 51, 56, 52, 50,
      51, 46, 48, 49, 50, 51, 48, 54, 50, 50, 50, 51,
      53, 49, 48, 49, 51, 55, 52, 52, 52, 50, 53, 51,
      46, 23
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.34, 0.44,  0.4,
      0.42, 0.43, 0.43, 0.45,
      0.44, 0.43, 0.43, 0.42,
      0.43, 0.19, 0.04, 0.03,
      0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.01, 0.25, 0.27, 0.27,
      0.29, 0.28, 0.28, 0.26,
      0.27, 0.27, 0.28, 0.28,
      0.26, 0.12, 0.03, 0.02,
      0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.02, 0.12, 0.72, 0.75,
      0.74, 0.75, 0.74, 0.73,
      0.74, 0.75, 0.74, 0.74,
      0.75, 0.74, 0.05, 0.02,
      0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.06, 0.24, 0.25,
      0.25, 0.25, 0.24, 0.25,
      0.25, 0.24, 0.26, 0.25,
      0.24, 0.25, 0.03, 0.02,
      0.02, 0.02
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

ASP.NET Core is performing well here. EF Core is incredibly efficient by default without any tuning headaches as it was with Sping Boot.

#### ASP.NET Core scenario 2

Iteration creation rate = **10/s**

```txt
checks.........................: 100.00% â 155200     â 0
data_received..................: 946 MB  13 MB/s
data_sent......................: 14 MB   191 kB/s
dropped_iterations.............: 501     6.896565/s
http_req_blocked...............: avg=7.71Âµs   min=194ns   med=532ns   max=58.81ms  p(90)=794ns    p(95)=926ns
http_req_connecting............: avg=342ns    min=0s      med=0s      max=8.25ms   p(90)=0s       p(95)=0s
http_req_duration..............: avg=21.65ms  min=1.63ms  med=15.74ms max=322.81ms p(90)=45.46ms  p(95)=58.96ms
  { expected_response:true }...: avg=21.65ms  min=1.63ms  med=15.74ms max=322.81ms p(90)=45.46ms  p(95)=58.96ms
http_req_failed................: 0.00%   â 0          â 155200
http_req_receiving.............: avg=1.78ms   min=19.8Âµs  med=848.9Âµs max=68.46ms  p(90)=4.39ms   p(95)=6.92ms
http_req_sending...............: avg=105.11Âµs min=17.95Âµs med=80.74Âµs max=44.98ms  p(90)=133.41Âµs p(95)=169.13Âµs
http_req_tls_handshaking.......: avg=6.35Âµs   min=0s      med=0s      max=37.09ms  p(90)=0s       p(95)=0s
http_req_waiting...............: avg=19.76ms  min=0s      med=13.7ms  max=320.85ms p(90)=42.87ms  p(95)=56.35ms
http_reqs......................: 155200  2136.42093/s
iteration_duration.............: avg=33.97s   min=29.96s  med=34.26s  max=36.95s   p(90)=35.59s   p(95)=35.78s
iterations.....................: 100     1.37656/s
vus............................: 15      min=10       max=50
vus_max........................: 50      min=50       max=50
```

{{< tabs >}}
{{< tab tabName="Req/s" >}}

{{< chart type="timeseries" title="Req/s count" >}}
[
  {
    label: 'Req/s',
    data: [
       152, 1336, 1692, 1841, 2152, 2221, 2151, 2160,
      2149, 2278, 2271, 2110, 2120, 1955, 2258, 2304,
      2194, 2034, 2295, 2273, 2222, 2189, 2153, 2166,
      2190, 2206, 2020, 2213, 2182, 2205, 2365, 2172,
      2177, 2060, 2274, 2279, 2183, 2060, 2085, 2237,
      2292, 2221, 2196, 1923, 2298, 2210, 2104, 2181,
      2044, 2285, 2364, 2224, 2054, 2178, 2226, 2405,
      2215, 2137, 2115, 2255, 2155, 2200, 2125, 2131,
      2308, 2303, 2130, 2105, 2092, 2251, 2222, 1987,
      1633,   47
    ]
  }
]
{{< /chart >}}

{{< /tab >}}

{{< tab tabName="Req duration" >}}

{{< chart type="timeseries" title="VUs count" >}}
[
  {
    label: 'VUs',
    data: [
      10, 20, 30, 40, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 49, 50,
      49, 50, 47, 49, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
      50, 50, 50, 50, 50, 48, 45, 42, 41, 35, 27, 15
    ]
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="Request duration in ms" >}}
[
  {
    label: 'Duration (ms)',
    data: [
       7,  7, 11, 16, 18, 22, 23, 23, 23, 22, 22, 23,
      23, 25, 22, 21, 22, 24, 21, 22, 23, 22, 23, 23,
      23, 22, 24, 22, 23, 23, 21, 23, 23, 23, 23, 22,
      23, 24, 23, 21, 22, 22, 22, 26, 21, 22, 24, 22,
      24, 22, 21, 22, 24, 22, 23, 21, 22, 23, 23, 22,
      23, 23, 24, 22, 22, 21, 22, 21, 20, 18, 15, 13,
       9,  4
    ]
  }
]
{{< /chart >}}

{{< /tab >}}
{{< tab tabName="CPU load" >}}

{{< chart type="timeseries" title="CPU runtime load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.28, 0.51, 0.52,
      0.53, 0.54, 0.52, 0.53,
      0.53, 0.54, 0.52, 0.52,
      0.52, 0.54, 0.54, 0.44,
      0.04, 0.03, 0.02
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.22,  0.4, 0.39,
      0.38, 0.37, 0.39, 0.37,
      0.39, 0.38, 0.42,  0.4,
       0.4, 0.38, 0.38, 0.31,
      0.03, 0.02, 0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< chart type="timeseries" title="CPU database load" stacked="true" max="1" step="5" >}}
[
  {
    label: 'User',
    data: [
      0.03, 0.02, 0.38, 0.52,
      0.51, 0.52, 0.52, 0.52,
      0.53, 0.52, 0.52, 0.51,
      0.52, 0.51, 0.54, 0.52,
      0.25, 0.03, 0.03
    ],
    borderColor: '#4bc0c0',
    backgroundColor: '#4bc0c0',
    fill: true
  },
  {
    label: 'System',
    data: [
      0.02, 0.02, 0.32, 0.38,
      0.37, 0.36, 0.37, 0.36,
      0.37, 0.36, 0.35, 0.39,
      0.38, 0.39, 0.37, 0.38,
      0.17, 0.02, 0.03
    ],
    borderColor: '#ff6384',
    backgroundColor: '#ff6384',
    fill: true
  }
]
{{< /chart >}}

{{< /tab >}}
{{< /tabs >}}

Not that far to Java variant, just a bit behind. But as workers are fully loaded here, contrary to Spring Boot which is limited by database, Java stays by far the clear winner for raw performance (in sacrifice of some memory obviously).

### Conclusion

Here are the final req/s results for each framework against PgSQL database.

{{< chart type="timeseries" title="Database intensive Scenario" >}}
[
  {
    label: "Laravel",
    borderColor: "#c2410c",
    backgroundColor: "#c2410c",
    data: [
      8, 83, 208, 275, 431, 479, 510, 536, 513, 589, 600, 578, 584, 589, 616,
      611, 581, 621, 597, 608, 649, 579, 607, 594, 635, 646, 570, 622, 576, 626,
      641, 607, 623, 603, 614, 623, 602, 614, 617, 645, 628, 570, 603, 599, 646,
      632, 622, 614, 592, 591, 647, 614, 613, 623, 612, 610, 624, 627, 613, 640,
      623, 574, 584, 586, 630, 613, 608, 634, 603, 640, 643, 616, 627, 607, 629,
      631, 628, 624, 626, 640, 622, 576, 636, 619, 647, 646, 596, 625, 606, 634,
      361,
    ],
  },
  {
    label: "Symfony",
    borderColor: "#ffffff",
    backgroundColor: "#ffffff",
    data: [
      75, 346, 355, 351, 351, 331, 347, 356, 349, 355, 327, 343, 338, 352, 349,
      326, 356, 349, 350, 354, 327, 350, 345, 347, 341, 329, 352, 351, 352, 353,
      331, 357, 355, 350, 351, 314, 350, 355, 351, 357, 330, 354, 355, 350, 353,
      323, 351, 346, 344, 356, 323, 355, 343, 351, 355, 322, 354, 353, 336, 354,
      328, 352, 354, 346, 64,
    ],
  },
  {
    label: "FastAPI",
    borderColor: "#0f766e",
    backgroundColor: "#0f766e",
    data: [
      345, 451, 480, 469, 476, 507, 461, 476, 523, 494, 467, 493, 476, 501, 483,
      502, 456, 467, 502, 465, 480, 476, 460, 488, 513, 507, 449, 477, 467, 488,
      496, 461, 467, 468, 508, 515, 444, 470, 496, 495, 496, 490, 453, 513, 491,
      481, 441, 471, 520, 463, 495, 457, 484, 454, 475, 467, 462, 479, 459, 481,
      504, 470, 210,
    ],
  },
  {
    label: "NestJS",
    borderColor: "#b91c1c",
    backgroundColor: "#b91c1c",
    data: [
      209, 657, 702, 731, 710, 709, 685, 759, 770, 744, 743, 767, 751, 750, 755,
      755, 738, 771, 764, 735, 751, 725, 750, 759, 750, 762, 733, 758, 778, 755,
      739, 745, 787, 767, 755, 765, 736, 790, 786, 760, 754, 745, 776, 781, 766,
      768, 698, 791, 755, 744, 749, 741, 790, 762, 775, 781, 756, 752, 769, 753,
      724, 714, 104,
    ],
  },
  {
    label: "Spring Boot",
    borderColor: "#15803d",
    backgroundColor: "#15803d",
    data: [
      48, 1270, 1532, 1558, 1625, 1613, 1419, 1497, 1628, 1514, 1605, 1489,
      1575, 1653, 1590, 1640, 1483, 1568, 1638, 1623, 1629, 1524, 1641, 1517,
      1616, 1592, 1525, 1613, 1712, 1674, 1598, 1531, 1554, 1584, 1616, 1606,
      1457, 1539, 1606, 1568, 1606, 1532, 1533, 1664, 1601, 1574, 1483, 1591,
      1665, 1662, 1590, 1537, 1585, 1624, 1603, 1585, 1514, 1552, 1681, 1592,
      1645, 987,
    ],
  },
  {
    label: "ASP.NET Core",
    borderColor: "#6d28d9",
    backgroundColor: "#6d28d9",
    data: [
      275, 849, 897, 867, 871, 966, 947, 937, 863,
      897, 905, 921, 908, 835, 914, 936, 927, 915,
      866, 924, 921, 928, 927, 875, 925, 933, 901,
      915, 874, 923, 943, 931, 933, 841, 884, 948,
      929, 939, 886, 925, 947, 938, 938, 841, 912,
      929, 935, 925, 895, 951, 927, 932, 917, 857,
      901, 926, 914, 928, 882, 912, 955, 627
    ],
  },
]
{{< /chart >}}

{{< chart type="timeseries" title="Runtime intensive Scenario" >}}
[
  {
    label: "Laravel",
    borderColor: "#c2410c",
    backgroundColor: "#c2410c",
    data: [
      8, 83, 208, 275, 431, 479, 510, 536, 513, 589, 600, 578, 584, 589, 616,
      611, 581, 621, 597, 608, 649, 579, 607, 594, 635, 646, 570, 622, 576, 626,
      641, 607, 623, 603, 614, 623, 602, 614, 617, 645, 628, 570, 603, 599, 646,
      632, 622, 614, 592, 591, 647, 614, 613, 623, 612, 610, 624, 627, 613, 640,
      623, 574, 584, 586, 630, 613, 608, 634, 603, 640, 643, 616, 627, 607, 629,
      631, 628, 624, 626, 640, 622, 576, 636, 619, 647, 646, 596, 625, 606, 634,
      361,
    ],
  },
  {
    label: "Symfony",
    borderColor: "#ffffff",
    backgroundColor: "#ffffff",
    data: [
      162, 449, 974, 1254, 1075, 1260, 1289, 1267, 1306, 1347, 1403, 1335, 1225,
      1431, 1295, 1330, 1365, 1344, 1461, 1369, 1461, 1398, 1310, 1460, 1412,
      1433, 1475, 1373, 1393, 1342, 1481, 1446, 1364, 1386, 1359, 1353, 1368,
      1316, 1386, 1258, 1451, 1502, 1327, 1419, 1327, 1339, 1389, 1373, 1388,
      1361, 1494, 1454, 1337, 1420, 1374, 1440, 1408, 1319, 1484, 1370, 1433,
      1329, 1334, 1393, 1415, 1347, 1399, 1412, 1320, 1290, 1508, 1401, 1312,
      1454, 1315, 1347, 1452, 1221, 1262, 1221, 1259, 1306, 676, 95,
    ],
  },
  {
    label: "FastAPI",
    borderColor: "#0f766e",
    backgroundColor: "#0f766e",
    data: [
      45, 176, 457, 647, 698, 657, 670, 671, 738, 801, 676, 783, 692, 700, 760,
      688, 743, 676, 698, 740, 695, 726, 763, 759, 723, 684, 774, 731, 740, 778,
      685, 792, 746, 755, 733, 682, 753, 730, 763, 735, 707, 792, 744, 695, 764,
      679, 778, 692, 775, 715, 675, 774, 712, 714, 742, 699, 719, 684, 762, 789,
      681, 752, 646, 722, 769, 651, 778, 743, 692, 764, 701, 736, 719, 816, 768,
      707, 765, 735, 762, 725, 701, 714, 652, 769, 784, 713, 703, 735, 767, 754,
      225,
    ],
  },
  {
    label: "NestJS",
    borderColor: "#b91c1c",
    backgroundColor: "#b91c1c",
    data: [
      18, 297, 824, 1140, 1286, 1523, 1425, 1587, 1485, 1517, 1692, 1669, 1610,
      1651, 1677, 1725, 1693, 1590, 1501, 1574, 1592, 1775, 1535, 1640, 1710,
      1633, 1699, 1524, 1680, 1653, 1787, 1752, 1658, 1680, 1655, 1754, 1763,
      1669, 1567, 1616, 1758, 1600, 1637, 1609, 1740, 1810, 1660, 1567, 1721,
      1510, 1771, 1786, 1631, 1634, 1671, 1767, 1754, 1649, 1682, 1500, 1708,
      1676, 1687, 1641, 1572, 1707, 1667, 1534, 1546, 1571, 1711, 1618, 1670,
      1703, 1613, 1784, 1677, 1713, 1672, 1679, 1716, 1698, 1369, 1662, 1637,
      1746, 1629, 1491, 852,
    ],
  },
  {
    label: "Spring Boot",
    borderColor: "#15803d",
    backgroundColor: "#15803d",
    data: [
      419, 1778, 2087, 2261, 2215, 2426, 2458, 2483, 2402, 2500, 2525, 2763,
      2426, 2634, 2587, 2568, 2740, 2495, 2510, 2458, 2533, 2615, 2392, 2553,
      2577, 2566, 2756, 2424, 2489, 2428, 2515, 2690, 2526, 2512, 2500, 2511,
      2658, 2473, 2468, 2473, 2593, 2633, 2481, 2558, 2527, 2491, 2672, 2613,
      2447, 2417, 2479, 2589, 2492, 2500, 2558, 2544, 2604, 2557, 2593, 2452,
      2635, 2598, 2361, 2414, 2066, 2025, 1951, 1988, 1869, 1881, 2023, 1734,
      85,
    ],
  },
  {
    label: "ASP.NET Core",
    borderColor: "#6d28d9",
    backgroundColor: "#6d28d9",
    data: [
       152, 1336, 1692, 1841, 2152, 2221, 2151, 2160,
      2149, 2278, 2271, 2110, 2120, 1955, 2258, 2304,
      2194, 2034, 2295, 2273, 2222, 2189, 2153, 2166,
      2190, 2206, 2020, 2213, 2182, 2205, 2365, 2172,
      2177, 2060, 2274, 2279, 2183, 2060, 2085, 2237,
      2292, 2221, 2196, 1923, 2298, 2210, 2104, 2181,
      2044, 2285, 2364, 2224, 2054, 2178, 2226, 2405,
      2215, 2137, 2115, 2255, 2155, 2200, 2125, 2131,
      2308, 2303, 2130, 2105, 2092, 2251, 2222, 1987,
      1633,   47
    ],
  },
]
{{< /chart >}}

To resume, compiled languages have always a clear advantage when it comes to raw performance.

Performance isn't the main criteria for a web framework. The DX is also very important, in that regard Laravel stays a very nice candidate, and you always have Octane for high performance if needed, while it's far less behind than Symfony.

As we have seen with Symfony, PHP is now really back in the game in terms of raw performance, almost competing against NodeJS and outperforming Python. And no more any headaches for worker configuration thanks to the excellent FrankenPHP runtime which provides production optimized docker images.

When it comes to compiled languages, I still personally prefer the DX of ASP.NET Core over Spring Boot. The performance gap is negligible, and it hasn't this warm up Java feeling and keeps a reasonable memory footprint.
